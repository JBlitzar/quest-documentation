<!DOCTYPE html>
<html>
  <head>
    <!--for now-->
    <meta name="robots" content="noindex" />

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link
      rel="preload"
      as="script"
      href="https://jblitzar.github.io/global.js"
    />
    <script src="https://jblitzar.github.io/global.js"></script>

    <!-- Google tag (gtag.js) -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-153400SX3J"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-153400SX3J");
    </script>

    <link
      rel="preload"
      as="style"
      href="https://jblitzar.github.io/global.css"
    />
    <link rel="stylesheet" href="https://jblitzar.github.io/global.css" />
    <link rel=icon href=https://jblitzar.github.io/favicon.png>
    <title>Quest Project</title>

    <style>
      a:visited {
        color: blue !important;
      }
      img {
        padding: 10px;
        border-radius: 30px;
      }
    </style>
  </head>
  <body class="container" style="max-width: 800px">
    <h2 style="margin-top: -25px">Independent Project-Based AI Research</h2>
    <h3>Jake Buckhouse</h3>
    <br />
    <div>
      <p>
        Go ahead and click in: README should have a brief description of the
        project, while NOTES should detail my process.
      </p>
      <ul>
        <li>
          <strong>Transformer-based Code Completion Model:</strong>
          <br />
          Inspired by state-of-the-art LLMs like ChatGPT, I created a
          transformer from scratch with Pytorch, implementing everything,
          including the attention mechanisms, myself. <br />
          <a
            href="https://github.com/JBlitzar/code-completion/blob/main/architecture.py"
            target="_blank"
            >https://github.com/JBlitzar/code-completion/blob/main/architecture.py</a
          >
          <br />
          <a href="https://github.com/JBlitzar/code-completion" target="_blank"
            >https://github.com/JBlitzar/code-completion#code-completion</a
          >
          <br />
            <div style="display: flex; justify-content: space-between;">
            <img
            src="images/attention.png"
            alt="Transformer Attention"
            style="width: 30%"
          />
          <img
            src="images/code-output.png"
            alt="Transformer Output"
            style="width: 30%"
          />

            
          </div>
          
          <br />
        </li>
        <li>
          <strong>Text to Image Diffusion Model:</strong><br />I coded a text to
          image diffusion model from scratch in Python with Pytorch. <br />
          <a
            href="https://github.com/JBlitzar/Text2Image/blob/main/README.md"
            target="_blank"
            >https://github.com/JBlitzar/Text2Image/blob/main/README.md</a
          >
          <a
            href="https://github.com/JBlitzar/Text2Image/blob/main/wrapper.py"
            target="_blank"
            >https://github.com/JBlitzar/Text2Image/blob/main/wrapper.py</a
          >
          <br />
          <a
            href="https://github.com/JBlitzar/Text2Image/blob/main/NOTES.md"
            target="_blank"
            >https://github.com/JBlitzar/Text2Image/blob/main/NOTES.md</a
          >
          <br />
          <img
            src="images/epoch_46_step_3999.png"
            alt="Text to Image Diffusion Model Result"
            style="width: 100%"
          />
          <br />
          <br />
        </li>
        <li>
          <strong>Saliency Maps for AI Explainability:</strong><br />Utilizes
          gradient-based methods for explainability. This tool allows you to see
          which parts of the image the model is most “paying attention to,”
          minimizing spurious correlation and overfitting. Coded from scratch in
          Python with Pytorch. <br />
          <a href="https://github.com/JBlitzar/saliency" target="_blank"
            >https://github.com/JBlitzar/saliency</a
          >
          <br />
          <img
            src="images/saliency.png"
            alt="Saliency Maps for AI Explainability"
            style="width: 100%"
          />
          <br />
          <br />
        </li>

        <li>
          <strong>NIH Chest X-ray Dataset Pneumonia Classification:</strong
          ><br />I created a simple CNN to classify images from the NIH Chest
          X-ray Dataset as either having or not having pneumonia. I was able to
          get 95% training accuracy and 82% validation accuracy. <br />
          <a href="https://github.com/JBlitzar/chest-xray" target="_blank"
            >https://github.com/JBlitzar/chest-xray</a
          >
          <br />
          <img
            src="images/chestxray.jpg"
            alt="NIH Chest X-ray Sample"
            style="width: 100%"
          />
          <br />
          <br />
        </li>

        <li>
          <strong>Genetic Graphs Neural Architecture Search System:</strong>
          Uses genetic algorithms to construct and evolve neural networks
          represented as Directed Acyclic Graphs in order to determine the
          optimal architecture. Coded from scratch in Python with Pytorch,
          utilizing the Pytorch Lightning training framework. <br />
          <a
            href="https://github.com/JBlitzar/genetic-graphs/blob/main/moduledag.py"
            target="_blank"
            >https://github.com/JBlitzar/genetic-graphs/blob/main/moduledag.py</a
          >
          <br />
          <img
            src="images/genetic_graphs.png"
            alt="Genetic Graphs Neural Architecture Search System"
            style="width: 100%"
          />
          <br />
        </li>
        <li>
          <strong>Adversarial Image Construction:</strong><br />Examining the
          limitations of CNNs by creating adversarial examples. Coded from
          scratch in Python with Pytorch. <br />
          <a
            href="https://github.com/JBlitzar/adversarial-attacks/blob/main/README.md"
            target="_blank"
            >https://github.com/JBlitzar/adversarial-attacks/blob/main/README.md</a
          >
          <br />
          <a
            href="https://github.com/JBlitzar/adversarial-attacks/blob/main/NOTES.txt"
            target="_blank"
            >https://github.com/JBlitzar/adversarial-attacks/blob/main/NOTES.txt</a
          >
          <br />
          <img
            src="images/adversarial.png"
            alt="Adversarial Image Construction Result"
            style="width: 100%"
          />
          <br />
        </li>
        <li>
          <strong>Symbolic Computation</strong><br />Essentially a derivative
          calculator. I created my own symbolic computation framework and
          applied knowledge from my calculus courses to recursively and
          symbolically (like a human, rather than estimating numerically)
          evaluate complex derivatives. Coded from scratch in Python with no
          external libraries.
          <br />
          <a
            href="https://github.com/JBlitzar/derivative/blob/main/modules.py"
            target="_blank"
            >https://github.com/JBlitzar/derivative/blob/main/modules.py</a
          >
          <br />
          <a href="https://github.com/JBlitzar/derivative" target="_blank"
            >https://github.com/JBlitzar/derivative</a
          >
          <br />
          <br />
        </li>
        <li>
          <strong>Constructive Counterfactuals for Targeted Finetuning:</strong>
          <br />
          This project introduces original research about Constructive
          Counterfactuals, based on Zheng Dai’s research. It demonstrates
          improved efficiency in finetuning by selecting only the most important
          samples, reducing computational cost.
          <br />
          <a
            href="https://github.com/JBlitzar/constructive-counterfactuals/blob/main/README.md"
            target="_blank"
            >https://github.com/JBlitzar/constructive-counterfactuals/blob/main/README.md</a
          >
          <br />
          <img
            src="images/counterfactuals.png"
            alt="Constructive Counterfactuals for Targeted Finetuning"
            style="width: 60%"
          />
          <br />
          <br />
        </li>
        <!--
        <li>
          <strong>Inpainting U-net Model:</strong><br />I coded an inpainting
          U-net model that reconstructs images when given missing data. Coded
          from scratch in Python with Pytorch. <br />
          <a
            href="https://github.com/JBlitzar/inpainting/blob/main/Results/Screenshot%202024-01-24%20at%201.49.21%20PM.png"  target="_blank"
            >https://github.com/JBlitzar/inpainting/blob/main/Results/Screenshot%202024-01-24%20at%201.49.21%20PM.png</a
          >
          <br />
          <a href="https://github.com/JBlitzar/inpainting" target="_blank"
            >https://github.com/JBlitzar/inpainting</a
          >
          <br />
          <img
            src="images/inpainting.png"
            alt="Inpainting U-net Model Result"
            style="width: 100%"
          />
          <br />
          <br />
        </li>
        -->
      </ul>
    </div>
  </body>
</html>
